{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bddzIh7J0WA6"
      },
      "outputs": [],
      "source": [
        "# Transformers installation\n",
        "! pip install transformers datasets\n",
        "# To install from source instead of the last release, comment the command above and uncomment the following one.\n",
        "# ! pip install git+https://github.com/huggingface/transformers.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugIHtiAo0WA9"
      },
      "source": [
        "# Multiple choice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8ck1MAD0WBA"
      },
      "source": [
        "## Load SWAG dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWTJYbEt0WBB"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "swag = load_dataset(\"swag\", \"regular\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUIp6hMy0WBC",
        "outputId": "1206a699-ae38-45cf-d5e4-860757c8b5e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ending0': 'passes by walking down the street playing their instruments.',\n",
              " 'ending1': 'has heard approaching them.',\n",
              " 'ending2': \"arrives and they're outside dancing and asleep.\",\n",
              " 'ending3': 'turns the lead singer watches the performance.',\n",
              " 'fold-ind': '3416',\n",
              " 'gold-source': 'gold',\n",
              " 'label': 0,\n",
              " 'sent1': 'Members of the procession walk down the street holding small horn brass instruments.',\n",
              " 'sent2': 'A drum line',\n",
              " 'startphrase': 'Members of the procession walk down the street holding small horn brass instruments. A drum line',\n",
              " 'video-id': 'anetv_jkn6uvmqwh4'}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "swag[\"train\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQx7JxnD0WBD"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6bZxW0D0WBE"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xveIAs5N0WBE"
      },
      "outputs": [],
      "source": [
        "ending_names = [\"ending0\", \"ending1\", \"ending2\", \"ending3\"]\n",
        "\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    first_sentences = [[context] * 4 for context in examples[\"sent1\"]]\n",
        "    question_headers = examples[\"sent2\"]\n",
        "    second_sentences = [\n",
        "        [f\"{header} {examples[end][i]}\" for end in ending_names] for i, header in enumerate(question_headers)\n",
        "    ]\n",
        "\n",
        "    first_sentences = sum(first_sentences, [])\n",
        "    second_sentences = sum(second_sentences, [])\n",
        "\n",
        "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
        "    return {k: [v[i : i + 4] for i in range(0, len(v), 4)] for k, v in tokenized_examples.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_hw0s1J0WBE"
      },
      "outputs": [],
      "source": [
        "tokenized_swag = swag.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_Qk5LIo0WBF"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
        "from typing import Optional, Union\n",
        "import torch\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorForMultipleChoice:\n",
        "    \"\"\"\n",
        "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenizer: PreTrainedTokenizerBase\n",
        "    padding: Union[bool, str, PaddingStrategy] = True\n",
        "    max_length: Optional[int] = None\n",
        "    pad_to_multiple_of: Optional[int] = None\n",
        "\n",
        "    def __call__(self, features):\n",
        "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
        "        labels = [feature.pop(label_name) for feature in features]\n",
        "        batch_size = len(features)\n",
        "        num_choices = len(features[0][\"input_ids\"])\n",
        "        flattened_features = [\n",
        "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
        "        ]\n",
        "        flattened_features = sum(flattened_features, [])\n",
        "\n",
        "        batch = self.tokenizer.pad(\n",
        "            flattened_features,\n",
        "            padding=self.padding,\n",
        "            max_length=self.max_length,\n",
        "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
        "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr5LIvrb0WBF"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-l_Lrlf90WBG"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNCkiTCg0WBG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U8lbfJm0WBG"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weBM6zEs0WBH"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForMultipleChoice.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iq5HagQu0WBH"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"my_awesome_swag_model\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    push_to_hub=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_swag[\"train\"],\n",
        "    eval_dataset=tokenized_swag[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GFHy4Di0WBH"
      },
      "outputs": [],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hawfey0U0WBI"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hdJQnUF0WBI"
      },
      "outputs": [],
      "source": [
        "prompt = \"France has a bread law, Le DÃ©cret Pain, with strict rules on what is allowed in a traditional baguette.\"\n",
        "candidate1 = \"The law does not apply to croissants and brioche.\"\n",
        "candidate2 = \"The law applies to baguettes.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXmUAtEI0WBI"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"my_awesome_swag_model\")\n",
        "inputs = tokenizer([[prompt, candidate1], [prompt, candidate2]], return_tensors=\"pt\", padding=True)\n",
        "labels = torch.tensor(0).unsqueeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ssuKXF60WBN"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForMultipleChoice\n",
        "\n",
        "model = AutoModelForMultipleChoice.from_pretrained(\"my_awesome_swag_model\")\n",
        "outputs = model(**{k: v.unsqueeze(0) for k, v in inputs.items()}, labels=labels)\n",
        "logits = outputs.logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3r6g6cK0WBN",
        "outputId": "698aed6b-fbea-41fe-d7c9-25f589517589"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'0'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_class = logits.argmax().item()\n",
        "predicted_class"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}